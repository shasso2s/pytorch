{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scaling_technik",
      "provenance": [],
      "mount_file_id": "1SIJdn-ojg8UEhXJViTUCnPn2iayLnD4w",
      "authorship_tag": "ABX9TyPFrnZD7rl/a06Vwb3eAP11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shasso2s/pytorch/blob/main/Scaling_technik.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su9fEGeqnEa2"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "# example of using ImageDataGenerator to normalize images\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YW-k9ziuVFr"
      },
      "source": [
        "**Normalization using ImageDataGenerator**\n",
        "*italicized text*\n",
        "In the following code we are using Pixel Normalization \n",
        "  * **Traget**: Normalization of Pixel values and transform it into range[0-1]\n",
        "Normaly the Pixel values are always between [0-255] , those values would be very high for the machine in case of procesing, therfore we use rescale(1/255) to put all the pixel value in this range.\n",
        "\n",
        "* Before we aply the scale we are reshaping all the images in one Size und Width(28*28) and channel =1 # RGB.\n",
        "* After that we are transforming the Label into categorical[0-10]\n",
        "\n",
        "* Imagedatagenaration is  a such a beatiful class that wrap the dataset , and make it in Batch with a specific size using **flow function**\n",
        "\n",
        "* **The ImageDataGenerator does not need to be fit in this case because there are no global statistics that need to be calculated.** therfore and in comparaison to other technique we don't use fit in scaling.\n",
        "\n",
        "* After scaling the pixel value and put dataset in form of Batch comes the step of model building , compiling, evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPK78Aq-nSNu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf7e02a-e4b4-4cf9-e360-ae1d8ac902cb"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "print('train',x_train.shape)\n",
        "print('test',x_test.shape)\n",
        "print('pixel value in x_train ',x_train.min(),x_train.max(),x_train.std(),x_train.mean())\n",
        "print('pixel value in x_test',x_test.min(),x_test.max(),x_test.std(),x_test.mean())\n",
        "width,height,channel=x_train.shape[1],x_train.shape[2],1\n",
        "x_train=x_train.reshape(x_train.shape[0],width,height,channel)\n",
        "x_test=x_test.reshape(x_test.shape[0],width,height,channel)\n",
        "y_train=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)\n",
        "print(\"train min=%.3f, max=%.3f\" %(x_train.min(),x_train.max()))\n",
        "print(\"test min=%.3f, test max=%.3f\"% (x_test.min(),x_test.max()))\n",
        "datagen=ImageDataGenerator(rescale=1.0/255.0)\n",
        "train_iterator=datagen.flow(x_train,y_train,batch_size=64)\n",
        "test_iterator=datagen.flow(x_test,y_test,batch_size=64)\n",
        "print(\"batches train , test\", len(train_iterator),len(test_iterator))\n",
        "batchx,batchy=train_iterator.next()\n",
        "print('batchx shape=%s , batchx_min=%.3f, batchx_max=%.3f'% (batchx.shape,batchx.min(), batchx.max()))\n",
        "import tensorflow as tf\n",
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(width,height,channel)),\n",
        "                           tf.keras.layers.MaxPooling2D(2,2),\n",
        "                           tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "                           tf.keras.layers.MaxPooling2D(2,2),\n",
        "                           tf.keras.layers.Flatten(),\n",
        "                           tf.keras.layers.Dense(64,activation='relu'),\n",
        "                           tf.keras.layers.Dense(10,activation='softmax')])\n",
        "# compile the model:\n",
        "model.compile(optimizer='adam',loss=tf.keras.metrics.categorical_crossentropy,metrics=['accuracy'])\n",
        "# fit the model:\n",
        "model.fit_generator(train_iterator,steps_per_epoch =len(train_iterator),epochs=5)\n",
        "#evalaute the model:\n",
        "_,acc=model.evaluate_generator(test_iterator,steps=len(test_iterator),verbose=0)\n",
        "print('Test accuracy:%.3f'%(acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train (60000, 28, 28)\n",
            "test (10000, 28, 28)\n",
            "pixel value in x_train  0 255 78.56748998339798 33.318421449829934\n",
            "pixel value in x_test 0 255 79.17246322228644 33.791224489795916\n",
            "train min=0.000, max=255.000\n",
            "test min=0.000, test max=255.000\n",
            "batches train , test 938 157\n",
            "batchx shape=(64, 28, 28, 1) , batchx_min=0.000, batchx_max=1.000\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 [==============================] - 51s 54ms/step - loss: 0.1642 - accuracy: 0.9514\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 50s 54ms/step - loss: 0.0536 - accuracy: 0.9837\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 50s 54ms/step - loss: 0.0373 - accuracy: 0.9885\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 51s 54ms/step - loss: 0.0293 - accuracy: 0.9908\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 50s 54ms/step - loss: 0.0223 - accuracy: 0.9928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy:98.910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njWpiv835Sl1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUn7d6maCeBM"
      },
      "source": [
        "**Pixel Centering**: scale pixel values to have a zero mean.\n",
        "* Another popular pixel scaling method is to calculate the mean pixel value across the entire training dataset, then subtract it from each image.\n",
        "\n",
        "* This is called centering and has the effect of centering the distribution of pixel values on zero: that is, the mean pixel value for centered images will be zero.\n",
        "* **datagen = ImageDataGenerator(featurewise_center=True)** this code alow us to achieve pixel centering , after that comes fit, anf flow function \n",
        "* the next steps is exactly the same as Scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTB0kVfZCqUF",
        "outputId": "512eba4d-4c01-43f0-ede7-01ec0cef9ca5"
      },
      "source": [
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = trainX.shape[1], trainX.shape[2], 1\n",
        "trainX = trainX.reshape((trainX.shape[0], width, height, channels))\n",
        "testX = testX.reshape((testX.shape[0], width, height, channels))\n",
        "# one hot encode target values\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)\n",
        "# create generator to center images\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "# calculate mean on training dataset\n",
        "datagen.fit(trainX)\n",
        "# prepare an iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(width, height, channels)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "# compile model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit model with generator\n",
        "model.fit_generator(train_iterator, steps_per_epoch=len(train_iterator), epochs=5)\n",
        "# evaluate model\n",
        "_, acc = model.evaluate_generator(test_iterator, steps=len(test_iterator), verbose=0)\n",
        "print('Test Accuracy: %.3f' % (acc * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches train=938, test=157\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938/938 [==============================] - 49s 52ms/step - loss: 0.4301 - accuracy: 0.9255\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 48s 51ms/step - loss: 0.0678 - accuracy: 0.9799\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 47s 50ms/step - loss: 0.0487 - accuracy: 0.9850\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 52s 55ms/step - loss: 0.0389 - accuracy: 0.9882\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 0.0379 - accuracy: 0.9880\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVnPD_SiijfG"
      },
      "source": [
        "t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bs_QGY1m0Mo"
      },
      "source": [
        "**How to Standardize Image with ImageDataGenerator **\n",
        "Standardization of images is achieved by substracting the mean pixel value and dividing the result by the standard deviation of the pixel values\n",
        "* **datagen=ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czDV2Uz0hs9h",
        "outputId": "9b74ef26-e8e9-45d9-ad81-0210dca50b64"
      },
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "width,height,channel=x_train.shape[1],x_train.shape[2],1\n",
        "x_train=x_train.reshape(x_train.shape[0],width,height,channel)\n",
        "x_test=x_test.reshape(x_test.shape[0],width,height,channel)\n",
        "y_train=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)\n",
        "datagen=ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)\n",
        "datagen.fit(x_train)\n",
        "x_train_iterator=datagen.flow(x_train,y_train,batch_size=64)\n",
        "y_test_iterator=datagen.flow(x_test,y_test,batch_size=64)\n",
        "batchx,batchy=x_train_iterator.next()\n",
        "# model\n",
        "model=tf.keras.Sequential([\n",
        "                           tf.keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(width,height,channel)),\n",
        "                           tf.keras.layers.MaxPooling2D(2,2),\n",
        "                           tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n",
        "                           tf.keras.layers.MaxPooling2D(2,2),\n",
        "                           tf.keras.layers.Flatten(),\n",
        "                           tf.keras.layers.Dense(64,activation='relu'),\n",
        "                           tf.keras.layers.Dense(10,activation='softmax')])\n",
        "#compile the model:\n",
        "model.compile(optimizer='adam',loss=tf.keras.metrics.categorical_crossentropy,metrics=['accuracy'])                        \n",
        "\n",
        "#fit the model:\n",
        "model.fit_generator(x_train_iterator,steps_per_epoch=len(x_train_iterator),epochs=5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 50s 53ms/step - loss: 0.1392 - accuracy: 0.9590\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 48s 52ms/step - loss: 0.0430 - accuracy: 0.9870\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 48s 51ms/step - loss: 0.0297 - accuracy: 0.9907\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 0.0237 - accuracy: 0.9927\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 49s 52ms/step - loss: 0.0179 - accuracy: 0.9941\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f64cec1e4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRwguIG2rtOI",
        "outputId": "ad6c2560-bf9d-4442-f9a8-79862e404337"
      },
      "source": [
        " _,acc=model.evaluate_generator(y_test_iterator,steps=len(y_test_iterator),verbose=0)\n",
        "print('acuracy:%.3f' %(acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acuracy:99.080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-s_fK9HruMX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}